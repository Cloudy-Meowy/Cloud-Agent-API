{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"/path/to/your/folder\"\n",
    "ES_CLOUD_ID = \"your_elasticsearch_cloud_id\"\n",
    "INDEX_NAME = \"your_index_name\"\n",
    "ES_USER = \"your_elasticsearch_username\"\n",
    "ES_PASSWORD = \"your_elasticsearch_password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55808d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader, UnstructuredWordDocumentLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "'''\n",
    "Load document và chia thành các chunk để đẩy vào elasticsearch\n",
    "'''\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for file in glob(os.path.join(folder_path, \"*\")):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyMuPDFLoader(file)\n",
    "        elif file.endswith(\".docx\"):\n",
    "            loader = UnstructuredWordDocumentLoader(file)\n",
    "        else:\n",
    "            continue\n",
    "        docs = loader.load()\n",
    "        documents.extend(docs)\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "docs = load_documents_from_folder(FOLDER_PATH)\n",
    "split_docs = split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023291a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "đẩy các chunk documents vào elasticsearch\n",
    "'''\n",
    "\n",
    "def create_elasticsearch_store(docs):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    elastic_vector_store = ElasticsearchStore.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        es_cloud_id=ES_CLOUD_ID,\n",
    "        index_name=INDEX_NAME,\n",
    "        es_user=ES_USER,\n",
    "        es_password=ES_PASSWORD,\n",
    "    )\n",
    "    return elastic_vector_store\n",
    "elasticsearch_store = create_elasticsearch_store(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709750bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_connection = Elasticsearch(\n",
    "    cloud_id=ES_CLOUD_ID,\n",
    "    basic_auth=(ES_USER, ES_PASSWORD),\n",
    ")\n",
    "\n",
    "elasticsearch_store = ElasticsearchStore(\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"),\n",
    "    index_name=INDEX_NAME,\n",
    "    es_connection=es_connection,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
